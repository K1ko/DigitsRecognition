{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Neural Networks with PyTorch\n",
    "This neural network will be able to recognize handwritten digits. We will use the MNIST dataset to train the neural network. The MNIST dataset consists of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 0 to 9."
   ],
   "id": "4db920d57cb8008a"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-17T13:10:20.674820Z",
     "start_time": "2024-08-17T13:10:15.129929Z"
    }
   },
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [],
   "id": "a280784417cbf58"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T13:11:53.386737Z",
     "start_time": "2024-08-17T13:11:53.310421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the dataset into training and test datasets\n",
    "train_data = datasets.MNIST(\n",
    "    root= 'data',\n",
    "    train = True,\n",
    "    transform= ToTensor(),\n",
    "    download= True\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root= 'data',\n",
    "    train = False,\n",
    "    transform= ToTensor(),\n",
    "    download= True\n",
    ")"
   ],
   "id": "970b757ef38a3405",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T13:11:54.393690Z",
     "start_time": "2024-08-17T13:11:54.386308Z"
    }
   },
   "cell_type": "code",
   "source": "train_data       ",
   "id": "6fc50121d57acc21",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T13:11:55.151972Z",
     "start_time": "2024-08-17T13:11:55.146977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_data"
   ],
   "id": "2de0f2960a1e174f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T13:11:55.892514Z",
     "start_time": "2024-08-17T13:11:55.887795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data.data.shape"
   ],
   "id": "ad27ab8cfdf9326f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T13:11:56.573728Z",
     "start_time": "2024-08-17T13:11:56.569346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_data.data.shape"
   ],
   "id": "74f1fab40d1f874f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T13:11:57.054226Z",
     "start_time": "2024-08-17T13:11:57.037019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data.targets  "
   ],
   "id": "cf00acc644abe6f1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T13:11:59.067903Z",
     "start_time": "2024-08-17T13:11:59.064267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "    'train': DataLoader(train_data,   \n",
    "                        batch_size= 100,  \n",
    "                        shuffle= True,\n",
    "                        num_workers= 1), \n",
    "    'test': DataLoader(test_data, \n",
    "                       batch_size= 100, \n",
    "                       shuffle= True,\n",
    "                       num_workers=1)\n",
    "}"
   ],
   "id": "8e02090491121472",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T13:12:00.560629Z",
     "start_time": "2024-08-17T13:12:00.556271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loaders"
   ],
   "id": "29954e7c04f91419",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x2e5d2193140>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x2e5d1e199a0>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T13:12:01.379799Z",
     "start_time": "2024-08-17T13:12:01.372102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"CNN Structure\"\"\"\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2)) # First layer\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320) # Flatten the data\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training= self.training) # Dropout triggers only during training not evaluation\n",
    "        x = self.fc2(x) \n",
    "        \n",
    "        return F.log_softmax(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ],
   "id": "8128b32a0a556f99",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T13:12:09.874229Z",
     "start_time": "2024-08-17T13:12:09.862854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr= 0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward() # Backpropagation\n",
    "        optimizer.step() # Update the weights\n",
    "        \n",
    "        if batch_idx % 20 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(loaders['train'].dataset),\n",
    "                100. * batch_idx / len(loaders['train']), loss.item()))\n",
    "def test():\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders['test']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item() # Need to shape the target as the prediction\n",
    "    \n",
    "    test_loss /= len(loaders['test'].dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(loaders['test'].dataset),\n",
    "        100. * correct / len(loaders['test'].dataset)))\n",
    "            \n",
    "        "
   ],
   "id": "37a6cfedebce145b",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T13:14:42.673034Z",
     "start_time": "2024-08-17T13:12:10.815391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(1, 11):\n",
    "    train(epoch)\n",
    "    test()"
   ],
   "id": "84367d750094395a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_22348\\1159085038.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.309020\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.185569\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 1.787831\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 1.074570\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.942187\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.713482\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.696955\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.737601\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.712487\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.398219\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.617146\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.480646\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.493979\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.468947\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.563268\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.363853\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.431642\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.246039\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.537362\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.473805\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.395711\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.504036\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.474856\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.499678\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.417511\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.313169\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.211299\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.325164\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.393816\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.459450\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 9608/10000 (96%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.340591\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.359377\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.425067\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.378075\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.533030\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.482560\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.346537\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.167218\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.409455\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.169509\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.264674\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.384921\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.413572\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.269131\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.233067\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.343148\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.161499\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.240967\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.337427\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.365693\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.188274\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.260132\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.385668\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.332181\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.340197\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.224992\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.175944\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.351964\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.257033\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.174271\n",
      "\n",
      "Test set: Average loss: 0.0009, Accuracy: 9713/10000 (97%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.163325\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.277929\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.246744\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.229598\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.217297\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.212823\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.163803\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.298425\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.238746\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.334837\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.345820\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.271342\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.182748\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.198170\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.366877\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.333020\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.134016\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.373058\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.159469\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.326407\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.320320\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.165702\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.248115\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.151372\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.198744\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.123591\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.138839\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.133666\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.229845\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.138366\n",
      "\n",
      "Test set: Average loss: 0.0007, Accuracy: 9778/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.162292\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.241869\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.197082\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.284286\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.127223\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.234664\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.247169\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.142184\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.164039\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.202425\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.237362\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.149647\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.236048\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.165205\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.102532\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.081789\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.206139\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.336454\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.290764\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.272319\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.271158\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.416754\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.242331\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.177721\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.383644\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.229524\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.289472\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.258002\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.135587\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.140515\n",
      "\n",
      "Test set: Average loss: 0.0007, Accuracy: 9805/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.188454\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.192614\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.269656\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.260460\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.147455\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.179296\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.157600\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.108033\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.270134\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.159207\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.211941\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.109909\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.059309\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.383494\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.239165\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.182698\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.218121\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.108023\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.140766\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.178658\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.165655\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.175096\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.326334\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.155786\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.164666\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.159863\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.102690\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.119876\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.230113\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.284172\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 9812/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.162247\n",
      "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 0.105191\n",
      "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 0.298609\n",
      "Train Epoch: 6 [6000/60000 (10%)]\tLoss: 0.141851\n",
      "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 0.091994\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.245960\n",
      "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.136698\n",
      "Train Epoch: 6 [14000/60000 (23%)]\tLoss: 0.179940\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.095339\n",
      "Train Epoch: 6 [18000/60000 (30%)]\tLoss: 0.218998\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.090820\n",
      "Train Epoch: 6 [22000/60000 (37%)]\tLoss: 0.229308\n",
      "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.246170\n",
      "Train Epoch: 6 [26000/60000 (43%)]\tLoss: 0.246606\n",
      "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 0.282297\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.182162\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.130629\n",
      "Train Epoch: 6 [34000/60000 (57%)]\tLoss: 0.140049\n",
      "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.169775\n",
      "Train Epoch: 6 [38000/60000 (63%)]\tLoss: 0.114436\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.159044\n",
      "Train Epoch: 6 [42000/60000 (70%)]\tLoss: 0.135085\n",
      "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 0.091230\n",
      "Train Epoch: 6 [46000/60000 (77%)]\tLoss: 0.269486\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.137129\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.075339\n",
      "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 0.158618\n",
      "Train Epoch: 6 [54000/60000 (90%)]\tLoss: 0.296899\n",
      "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 0.084929\n",
      "Train Epoch: 6 [58000/60000 (97%)]\tLoss: 0.122363\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 9813/10000 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.121220\n",
      "Train Epoch: 7 [2000/60000 (3%)]\tLoss: 0.329138\n",
      "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 0.102329\n",
      "Train Epoch: 7 [6000/60000 (10%)]\tLoss: 0.172323\n",
      "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 0.140313\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.143121\n",
      "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.144614\n",
      "Train Epoch: 7 [14000/60000 (23%)]\tLoss: 0.208567\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.094374\n",
      "Train Epoch: 7 [18000/60000 (30%)]\tLoss: 0.159619\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.269055\n",
      "Train Epoch: 7 [22000/60000 (37%)]\tLoss: 0.237108\n",
      "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.253897\n",
      "Train Epoch: 7 [26000/60000 (43%)]\tLoss: 0.097126\n",
      "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 0.101501\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.240730\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.099938\n",
      "Train Epoch: 7 [34000/60000 (57%)]\tLoss: 0.145159\n",
      "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.112835\n",
      "Train Epoch: 7 [38000/60000 (63%)]\tLoss: 0.131008\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.108195\n",
      "Train Epoch: 7 [42000/60000 (70%)]\tLoss: 0.173644\n",
      "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 0.151255\n",
      "Train Epoch: 7 [46000/60000 (77%)]\tLoss: 0.190216\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.130286\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.093664\n",
      "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 0.251399\n",
      "Train Epoch: 7 [54000/60000 (90%)]\tLoss: 0.172638\n",
      "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 0.104523\n",
      "Train Epoch: 7 [58000/60000 (97%)]\tLoss: 0.090326\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 9830/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.200814\n",
      "Train Epoch: 8 [2000/60000 (3%)]\tLoss: 0.102155\n",
      "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 0.130046\n",
      "Train Epoch: 8 [6000/60000 (10%)]\tLoss: 0.114590\n",
      "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 0.253291\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.057654\n",
      "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.143998\n",
      "Train Epoch: 8 [14000/60000 (23%)]\tLoss: 0.141323\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.323241\n",
      "Train Epoch: 8 [18000/60000 (30%)]\tLoss: 0.156174\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.306401\n",
      "Train Epoch: 8 [22000/60000 (37%)]\tLoss: 0.051671\n",
      "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.078872\n",
      "Train Epoch: 8 [26000/60000 (43%)]\tLoss: 0.195875\n",
      "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 0.047342\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.103471\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.072927\n",
      "Train Epoch: 8 [34000/60000 (57%)]\tLoss: 0.299473\n",
      "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.137994\n",
      "Train Epoch: 8 [38000/60000 (63%)]\tLoss: 0.115204\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.139852\n",
      "Train Epoch: 8 [42000/60000 (70%)]\tLoss: 0.262733\n",
      "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 0.106635\n",
      "Train Epoch: 8 [46000/60000 (77%)]\tLoss: 0.136476\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.166586\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.122814\n",
      "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 0.162578\n",
      "Train Epoch: 8 [54000/60000 (90%)]\tLoss: 0.175475\n",
      "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 0.165264\n",
      "Train Epoch: 8 [58000/60000 (97%)]\tLoss: 0.124772\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 9840/10000 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.166299\n",
      "Train Epoch: 9 [2000/60000 (3%)]\tLoss: 0.422325\n",
      "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 0.104818\n",
      "Train Epoch: 9 [6000/60000 (10%)]\tLoss: 0.210671\n",
      "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 0.085927\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.211976\n",
      "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.104622\n",
      "Train Epoch: 9 [14000/60000 (23%)]\tLoss: 0.081677\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.116589\n",
      "Train Epoch: 9 [18000/60000 (30%)]\tLoss: 0.116591\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.256939\n",
      "Train Epoch: 9 [22000/60000 (37%)]\tLoss: 0.077789\n",
      "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.096876\n",
      "Train Epoch: 9 [26000/60000 (43%)]\tLoss: 0.215132\n",
      "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 0.142355\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.200958\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.123441\n",
      "Train Epoch: 9 [34000/60000 (57%)]\tLoss: 0.060820\n",
      "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.216782\n",
      "Train Epoch: 9 [38000/60000 (63%)]\tLoss: 0.189187\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.150530\n",
      "Train Epoch: 9 [42000/60000 (70%)]\tLoss: 0.094511\n",
      "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 0.157070\n",
      "Train Epoch: 9 [46000/60000 (77%)]\tLoss: 0.112614\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.048077\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.091991\n",
      "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 0.238308\n",
      "Train Epoch: 9 [54000/60000 (90%)]\tLoss: 0.177226\n",
      "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 0.172077\n",
      "Train Epoch: 9 [58000/60000 (97%)]\tLoss: 0.121051\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 9850/10000 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.324302\n",
      "Train Epoch: 10 [2000/60000 (3%)]\tLoss: 0.142923\n",
      "Train Epoch: 10 [4000/60000 (7%)]\tLoss: 0.142371\n",
      "Train Epoch: 10 [6000/60000 (10%)]\tLoss: 0.291149\n",
      "Train Epoch: 10 [8000/60000 (13%)]\tLoss: 0.118921\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 0.185500\n",
      "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 0.082281\n",
      "Train Epoch: 10 [14000/60000 (23%)]\tLoss: 0.174788\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.095650\n",
      "Train Epoch: 10 [18000/60000 (30%)]\tLoss: 0.081419\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 0.118501\n",
      "Train Epoch: 10 [22000/60000 (37%)]\tLoss: 0.184653\n",
      "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 0.232619\n",
      "Train Epoch: 10 [26000/60000 (43%)]\tLoss: 0.150041\n",
      "Train Epoch: 10 [28000/60000 (47%)]\tLoss: 0.079979\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 0.071476\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.122116\n",
      "Train Epoch: 10 [34000/60000 (57%)]\tLoss: 0.086097\n",
      "Train Epoch: 10 [36000/60000 (60%)]\tLoss: 0.126593\n",
      "Train Epoch: 10 [38000/60000 (63%)]\tLoss: 0.165340\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 0.080343\n",
      "Train Epoch: 10 [42000/60000 (70%)]\tLoss: 0.099871\n",
      "Train Epoch: 10 [44000/60000 (73%)]\tLoss: 0.079172\n",
      "Train Epoch: 10 [46000/60000 (77%)]\tLoss: 0.080200\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.187972\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 0.178323\n",
      "Train Epoch: 10 [52000/60000 (87%)]\tLoss: 0.155677\n",
      "Train Epoch: 10 [54000/60000 (90%)]\tLoss: 0.156815\n",
      "Train Epoch: 10 [56000/60000 (93%)]\tLoss: 0.188433\n",
      "Train Epoch: 10 [58000/60000 (97%)]\tLoss: 0.147106\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 9862/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T13:14:48.026697Z",
     "start_time": "2024-08-17T13:14:48.022226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device # Check if the model is running on GPU"
   ],
   "id": "e94be50c39e1a068",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T13:14:57.182481Z",
     "start_time": "2024-08-17T13:14:56.676958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "\n",
    "data, target = test_data[4]\n",
    "\n",
    "data = data.unsqueeze(0).to(device)\n",
    "output = model(data)\n",
    "prediction = output.argmax(dim=1, keepdim=True).item()\n",
    "\n",
    "print(f'The prediction is: {prediction}')\n",
    "\n",
    "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ],
   "id": "c6090eb1819b6d39",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction is: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_22348\\1159085038.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAaz0lEQVR4nO3de2zV9f3H8dfhdrjYHqy1PS3XAgqbXIwMaqMijIa2GsJNA44/wBkJrphhpy5dFLxl3VjmjEvF/bGBZoKXRSCyhQUrLXErOCqEkLmGdp3UQMtg6TmlQCHt5/cH8fw8Ui7fwzl9t6fPR/JN7DnfT79vvzvy3Lfn8K3POecEAEA362c9AACgbyJAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADAxADrAb6ts7NTx48fV0pKinw+n/U4AACPnHNqbW1Vdna2+vW78nVOjwvQ8ePHNWrUKOsxAAA3qLGxUSNHjrzi8z3uR3ApKSnWIwAA4uBaf54nLEDl5eUaO3asBg8erNzcXH322WfXtY4fuwFAcrjWn+cJCdB7772nkpISrV+/Xp9//rmmTZumgoICnTx5MhGHAwD0Ri4BZs6c6YqLiyNfd3R0uOzsbFdWVnbNtaFQyEliY2NjY+vlWygUuuqf93G/Arpw4YJqamqUn58feaxfv37Kz89XdXX1Zfu3t7crHA5HbQCA5Bf3AJ06dUodHR3KzMyMejwzM1NNTU2X7V9WVqZAIBDZ+AQcAPQN5p+CKy0tVSgUimyNjY3WIwEAukHc/x5Qenq6+vfvr+bm5qjHm5ubFQwGL9vf7/fL7/fHewwAQA8X9yugQYMGafr06aqoqIg81tnZqYqKCuXl5cX7cACAXiohd0IoKSnRihUr9L3vfU8zZ87Ua6+9pra2Nj366KOJOBwAoBdKSICWLl2q//73v1q3bp2ampp05513ateuXZd9MAEA0Hf5nHPOeohvCofDCgQC1mMAAG5QKBRSamrqFZ83/xQcAKBvIkAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwMsB4AuJa77rrL85oPP/wwpmONHTs2pnWIzbx58zyv+eKLLzyvaWxs9LwGiccVEADABAECAJiIe4BeeOEF+Xy+qG3SpEnxPgwAoJdLyHtAd9xxhz7++OP/P8gA3moCAERLSBkGDBigYDCYiG8NAEgSCXkP6OjRo8rOzta4ceO0fPlyHTt27Ir7tre3KxwOR20AgOQX9wDl5uZq8+bN2rVrlzZu3KiGhgbdd999am1t7XL/srIyBQKByDZq1Kh4jwQA6IHiHqCioiI9/PDDmjp1qgoKCvSXv/xFLS0tev/997vcv7S0VKFQKLLxeX0A6BsS/umA4cOH6/bbb1ddXV2Xz/v9fvn9/kSPAQDoYRL+94DOnDmj+vp6ZWVlJfpQAIBeJO4Bevrpp1VVVaX//Oc/+vvf/65Fixapf//+euSRR+J9KABALxb3H8F99dVXeuSRR3T69Gndeuutuvfee7Vv3z7deuut8T4UAKAXi3uA3n333Xh/S/RxBQUFntfwvmLvMH/+fM9rfvjDH3pes2zZMs9rkHjcCw4AYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMJHwX0gHfNOAAd5fcg888EACJkFPUFNT43lNSUmJ5zXDhg3zvEaS2traYlqH68MVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExwN2x0qzlz5nhek5eX53nNhg0bPK9B97v55ps9r/nud7/rec3QoUM9r5G4G3aicQUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjgZqSI2eTJkz2v2bp1q+c19fX1ntf8/Oc/97wG3W/BggXWI8AQV0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAluRoqYPffcc57XDBs2zPOawsJCz2vOnDnjeQ1uTFpamuc1999/v+c1nZ2dntegZ+IKCABgggABAEx4DtDevXs1f/58ZWdny+fzafv27VHPO+e0bt06ZWVlaciQIcrPz9fRo0fjNS8AIEl4DlBbW5umTZum8vLyLp/fsGGDXn/9db355pvav3+/hg0bpoKCAp0/f/6GhwUAJA/PH0IoKipSUVFRl8855/Taa6/pueeei/ymw7fffluZmZnavn27li1bdmPTAgCSRlzfA2poaFBTU5Py8/MjjwUCAeXm5qq6urrLNe3t7QqHw1EbACD5xTVATU1NkqTMzMyoxzMzMyPPfVtZWZkCgUBkGzVqVDxHAgD0UOafgistLVUoFIpsjY2N1iMBALpBXAMUDAYlSc3NzVGPNzc3R577Nr/fr9TU1KgNAJD84hqgnJwcBYNBVVRURB4Lh8Pav3+/8vLy4nkoAEAv5/lTcGfOnFFdXV3k64aGBh06dEhpaWkaPXq01q5dq1deeUW33XabcnJy9Pzzzys7O1sLFy6M59wAgF7Oc4AOHDigOXPmRL4uKSmRJK1YsUKbN2/Ws88+q7a2Nq1atUotLS269957tWvXLg0ePDh+UwMAej2fc85ZD/FN4XBYgUDAeow+5aGHHopp3R/+8AfPa7788kvPa6ZMmeJ5Dbrfr3/9a89r1q5d63lNZWWl5zWx3NBWki5evBjTOlwSCoWu+r6++afgAAB9EwECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEx4/nUMSD4PP/xwTOuGDh3qec0bb7wR07HQvcaOHet5zfLlyz2v6ejo8LzmlVde8byGu1r3TFwBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmuBlpkgkEAp7X3H333QmYpGsbN27stmMhdqtWrfK8Jj093fOaL774wvOaPXv2eF6DnokrIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABDcjTTJ+v9/zmhEjRsR0rK1bt8a0Dj3f+PHju+U4R44c6ZbjoGfiCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHNSJNMa2ur5zWHDh2K6VhTp071vCYtLc3zmv/973+e1+CSjIyMmNY99NBDcZ6ka59++mm3HAc9E1dAAAATBAgAYMJzgPbu3av58+crOztbPp9P27dvj3p+5cqV8vl8UVthYWG85gUAJAnPAWpra9O0adNUXl5+xX0KCwt14sSJyMYvLgMAfJvnDyEUFRWpqKjoqvv4/X4Fg8GYhwIAJL+EvAdUWVmpjIwMTZw4UU888YROnz59xX3b29sVDoejNgBA8ot7gAoLC/X222+roqJCv/zlL1VVVaWioiJ1dHR0uX9ZWZkCgUBkGzVqVLxHAgD0QHH/e0DLli2L/POUKVM0depUjR8/XpWVlZo7d+5l+5eWlqqkpCTydTgcJkIA0Ack/GPY48aNU3p6uurq6rp83u/3KzU1NWoDACS/hAfoq6++0unTp5WVlZXoQwEAehHPP4I7c+ZM1NVMQ0ODDh06pLS0NKWlpenFF1/UkiVLFAwGVV9fr2effVYTJkxQQUFBXAcHAPRungN04MABzZkzJ/L11+/frFixQhs3btThw4f11ltvqaWlRdnZ2Zo3b55efvll+f3++E0NAOj1PAdo9uzZcs5d8fm//vWvNzQQbsy5c+c8r6mvr4/pWEuWLPG85s9//rPnNa+++qrnNT3d5MmTPa8ZN26c5zVjx471vEbSVf8bj6fOzs5uOQ56Ju4FBwAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABM+1123vb1O4XBYgUDAeow+ZdKkSTGte+mllzyvefDBBz2vScZf5XHq1CnPa2L5TzU9Pd3zGkny+XwxrfMqJSXF85pY7vgOG6FQ6Kq/5ZorIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABDcjRbe68847Pa+ZMGFC/Acx9qc//albjvPWW2/FtG758uVxnqRrAwYM6JbjwAY3IwUA9EgECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAnuBIhudejQoW5Zg0v+/e9/W49wVZMnT/a85siRIwmYBBa4AgIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATHAzUiCJ+Xy+bl3nFTcW7du4AgIAmCBAAAATngJUVlamGTNmKCUlRRkZGVq4cKFqa2uj9jl//ryKi4t1yy236KabbtKSJUvU3Nwc16EBAL2fpwBVVVWpuLhY+/bt0+7du3Xx4kXNmzdPbW1tkX2eeuopffTRR/rggw9UVVWl48ePa/HixXEfHADQu3n6EMKuXbuivt68ebMyMjJUU1OjWbNmKRQK6fe//722bNmi73//+5KkTZs26Tvf+Y727dunu+++O36TAwB6tRt6DygUCkmS0tLSJEk1NTW6ePGi8vPzI/tMmjRJo0ePVnV1dZffo729XeFwOGoDACS/mAPU2dmptWvX6p577on8XvempiYNGjRIw4cPj9o3MzNTTU1NXX6fsrIyBQKByDZq1KhYRwIA9CIxB6i4uFhHjhzRu+++e0MDlJaWKhQKRbbGxsYb+n4AgN4hpr+IumbNGu3cuVN79+7VyJEjI48Hg0FduHBBLS0tUVdBzc3NCgaDXX4vv98vv98fyxgAgF7M0xWQc05r1qzRtm3b9MknnygnJyfq+enTp2vgwIGqqKiIPFZbW6tjx44pLy8vPhMDAJKCpyug4uJibdmyRTt27FBKSkrkfZ1AIKAhQ4YoEAjoscceU0lJidLS0pSamqonn3xSeXl5fAIOABDFU4A2btwoSZo9e3bU45s2bdLKlSslSb/5zW/Ur18/LVmyRO3t7SooKNAbb7wRl2EBAMnDU4Ccc9fcZ/DgwSovL1d5eXnMQwGIj+v5bzae6wAvuBccAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATMT0G1EB9A6DBw/utmOdO3eu246F5MAVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggpuRAkns0UcfjWldS0uL5zUvv/xyTMdC38UVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggpuRAknsH//4R0zrXn31Vc9r9uzZE9Ox0HdxBQQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmPA555z1EN8UDocVCASsxwAA3KBQKKTU1NQrPs8VEADABAECAJjwFKCysjLNmDFDKSkpysjI0MKFC1VbWxu1z+zZs+Xz+aK21atXx3VoAEDv5ylAVVVVKi4u1r59+7R7925dvHhR8+bNU1tbW9R+jz/+uE6cOBHZNmzYENehAQC9n6ffiLpr166orzdv3qyMjAzV1NRo1qxZkceHDh2qYDAYnwkBAEnpht4DCoVCkqS0tLSox9955x2lp6dr8uTJKi0t1dmzZ6/4Pdrb2xUOh6M2AEAf4GLU0dHhHnzwQXfPPfdEPf673/3O7dq1yx0+fNj98Y9/dCNGjHCLFi264vdZv369k8TGxsbGlmRbKBS6akdiDtDq1avdmDFjXGNj41X3q6iocJJcXV1dl8+fP3/ehUKhyNbY2Gh+0tjY2NjYbny7VoA8vQf0tTVr1mjnzp3au3evRo4cedV9c3NzJUl1dXUaP378Zc/7/X75/f5YxgAA9GKeAuSc05NPPqlt27apsrJSOTk511xz6NAhSVJWVlZMAwIAkpOnABUXF2vLli3asWOHUlJS1NTUJEkKBAIaMmSI6uvrtWXLFj3wwAO65ZZbdPjwYT311FOaNWuWpk6dmpB/AQBAL+XlfR9d4ed8mzZtcs45d+zYMTdr1iyXlpbm/H6/mzBhgnvmmWeu+XPAbwqFQuY/t2RjY2Nju/HtWn/2czNSAEBCcDNSAECPRIAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAw0eMC5JyzHgEAEAfX+vO8xwWotbXVegQAQBxc689zn+thlxydnZ06fvy4UlJS5PP5op4Lh8MaNWqUGhsblZqaajShPc7DJZyHSzgPl3AeLukJ58E5p9bWVmVnZ6tfvytf5wzoxpmuS79+/TRy5Mir7pOamtqnX2Bf4zxcwnm4hPNwCefhEuvzEAgErrlPj/sRHACgbyBAAAATvSpAfr9f69evl9/vtx7FFOfhEs7DJZyHSzgPl/Sm89DjPoQAAOgbetUVEAAgeRAgAIAJAgQAMEGAAAAmek2AysvLNXbsWA0ePFi5ubn67LPPrEfqdi+88IJ8Pl/UNmnSJOuxEm7v3r2aP3++srOz5fP5tH379qjnnXNat26dsrKyNGTIEOXn5+vo0aM2wybQtc7DypUrL3t9FBYW2gybIGVlZZoxY4ZSUlKUkZGhhQsXqra2Nmqf8+fPq7i4WLfccotuuukmLVmyRM3NzUYTJ8b1nIfZs2df9npYvXq10cRd6xUBeu+991RSUqL169fr888/17Rp01RQUKCTJ09aj9bt7rjjDp04cSKyffrpp9YjJVxbW5umTZum8vLyLp/fsGGDXn/9db355pvav3+/hg0bpoKCAp0/f76bJ02sa50HSSosLIx6fWzdurUbJ0y8qqoqFRcXa9++fdq9e7cuXryoefPmqa2tLbLPU089pY8++kgffPCBqqqqdPz4cS1evNhw6vi7nvMgSY8//njU62HDhg1GE1+B6wVmzpzpiouLI193dHS47OxsV1ZWZjhV91u/fr2bNm2a9RimJLlt27ZFvu7s7HTBYND96le/ijzW0tLi/H6/27p1q8GE3ePb58E551asWOEWLFhgMo+VkydPOkmuqqrKOXfpf/uBAwe6Dz74ILLPF1984SS56upqqzET7tvnwTnn7r//fvfjH//Ybqjr0OOvgC5cuKCamhrl5+dHHuvXr5/y8/NVXV1tOJmNo0ePKjs7W+PGjdPy5ct17Ngx65FMNTQ0qKmpKer1EQgElJub2ydfH5WVlcrIyNDEiRP1xBNP6PTp09YjJVQoFJIkpaWlSZJqamp08eLFqNfDpEmTNHr06KR+PXz7PHztnXfeUXp6uiZPnqzS0lKdPXvWYrwr6nE3I/22U6dOqaOjQ5mZmVGPZ2Zm6l//+pfRVDZyc3O1efNmTZw4USdOnNCLL76o++67T0eOHFFKSor1eCaampokqcvXx9fP9RWFhYVavHixcnJyVF9fr5/97GcqKipSdXW1+vfvbz1e3HV2dmrt2rW65557NHnyZEmXXg+DBg3S8OHDo/ZN5tdDV+dBkn7wgx9ozJgxys7O1uHDh/XTn/5UtbW1+vDDDw2njdbjA4T/V1RUFPnnqVOnKjc3V2PGjNH777+vxx57zHAy9ATLli2L/POUKVM0depUjR8/XpWVlZo7d67hZIlRXFysI0eO9In3Qa/mSudh1apVkX+eMmWKsrKyNHfuXNXX12v8+PHdPWaXevyP4NLT09W/f//LPsXS3NysYDBoNFXPMHz4cN1+++2qq6uzHsXM168BXh+XGzdunNLT05Py9bFmzRrt3LlTe/bsifr1LcFgUBcuXFBLS0vU/sn6erjSeehKbm6uJPWo10OPD9CgQYM0ffp0VVRURB7r7OxURUWF8vLyDCezd+bMGdXX1ysrK8t6FDM5OTkKBoNRr49wOKz9+/f3+dfHV199pdOnTyfV68M5pzVr1mjbtm365JNPlJOTE/X89OnTNXDgwKjXQ21trY4dO5ZUr4drnYeuHDp0SJJ61uvB+lMQ1+Pdd991fr/fbd682f3zn/90q1atcsOHD3dNTU3Wo3Wrn/zkJ66ystI1NDS4v/3tby4/P9+lp6e7kydPWo+WUK2tre7gwYPu4MGDTpJ79dVX3cGDB92XX37pnHPuF7/4hRs+fLjbsWOHO3z4sFuwYIHLyclx586dM548vq52HlpbW93TTz/tqqurXUNDg/v444/dXXfd5W677TZ3/vx569Hj5oknnnCBQMBVVla6EydORLazZ89G9lm9erUbPXq0++STT9yBAwdcXl6ey8vLM5w6/q51Hurq6txLL73kDhw44BoaGtyOHTvcuHHj3KxZs4wnj9YrAuScc7/97W/d6NGj3aBBg9zMmTPdvn37rEfqdkuXLnVZWVlu0KBBbsSIEW7p0qWurq7OeqyE27Nnj5N02bZixQrn3KWPYj///PMuMzPT+f1+N3fuXFdbW2s7dAJc7TycPXvWzZs3z916661u4MCBbsyYMe7xxx9Puv+T1tW/vyS3adOmyD7nzp1zP/rRj9zNN9/shg4d6hYtWuROnDhhN3QCXOs8HDt2zM2aNculpaU5v9/vJkyY4J555hkXCoVsB/8Wfh0DAMBEj38PCACQnAgQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE/8HidF32j++nCgAAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-17T10:09:47.759114Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "544ece95ad3590b1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
